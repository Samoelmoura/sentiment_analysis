{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b621b84",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdbc098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:40:23.259553Z",
     "start_time": "2022-04-10T19:40:20.142909Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f4b62",
   "metadata": {},
   "source": [
    "## 0.1 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032d899a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:40:26.021102Z",
     "start_time": "2022-04-10T19:40:23.259553Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\My Drive\\\\Pessoal\\\\Projetos\\\\sentiment_analysis\\\\training.1600000.processed.noemoticon.csv', header=None, encoding='latin1')\n",
    "\n",
    "df.columns= 'sentiment id date query user text'.split()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27c887",
   "metadata": {},
   "source": [
    "## 0.2 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406ee618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:40:26.037915Z",
     "start_time": "2022-04-10T19:40:26.021795Z"
    }
   },
   "outputs": [],
   "source": [
    "# data clean\n",
    "def clean_tweet(tweet):\n",
    "    tweet = BeautifulSoup(tweet, 'lxml').get_text()\n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+', ' ', tweet)\n",
    "    tweet = re.sub(r'https?://[A-Za-z0-9./]+', ' ', tweet)\n",
    "    tweet = re.sub(r\"[^A-Za-z.!?']\", ' ', tweet)\n",
    "    tweet = re.sub(r' +', ' ', tweet)\n",
    "    return tweet\n",
    "\n",
    "# encoding \n",
    "def encode_sentence(sent):\n",
    "    return token_model.convert_tokens_to_ids(token_model.tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29bc594",
   "metadata": {},
   "source": [
    "# 1.0 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b2134a",
   "metadata": {},
   "source": [
    "## 1.1 Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22876522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:40:26.057289Z",
     "start_time": "2022-04-10T19:40:26.041106Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H치 no total: 1600000 linhas\n",
      "H치 no total: 6 columnas\n"
     ]
    }
   ],
   "source": [
    "print(f'H치 no total: {df.shape[0]} linhas')\n",
    "print(f'H치 no total: {df.shape[1]} columnas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec64b83",
   "metadata": {},
   "source": [
    "## 1.2 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0b4e1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:40:26.073973Z",
     "start_time": "2022-04-10T19:40:26.057913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment     int64\n",
       "id            int64\n",
       "date         object\n",
       "query        object\n",
       "user         object\n",
       "text         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0746c4",
   "metadata": {},
   "source": [
    "## 1.3 Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82879a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:40:26.661262Z",
     "start_time": "2022-04-10T19:40:26.074396Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "id           0\n",
       "date         0\n",
       "query        0\n",
       "user         0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942860e4",
   "metadata": {},
   "source": [
    "# 2.0 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce439ba",
   "metadata": {},
   "source": [
    "###### 2.1.1 Changing positive sentiments values to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9faca0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:40:26.697205Z",
     "start_time": "2022-04-10T19:40:26.661262Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['sentiment']==4, 'sentiment'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b328a",
   "metadata": {},
   "source": [
    "###### 2.1.2 Removing Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7413a5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:45:11.154950Z",
     "start_time": "2022-04-10T19:40:26.697205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \" i just received my G8 viola exam.. and its... well... .. disappointing.. :\\..\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "D:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \"E3 ON PLAYSTATION HOME IN ABOUT AN HOUR!!!!!!!!!! \\../  \\../\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c402edf",
   "metadata": {},
   "source": [
    "# 3.0 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c313af5",
   "metadata": {},
   "source": [
    "## 3.1 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f97cecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:45:19.322164Z",
     "start_time": "2022-04-10T19:45:11.154950Z"
    }
   },
   "outputs": [],
   "source": [
    "# trained algotithm\n",
    "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bcd30aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:45:19.337928Z",
     "start_time": "2022-04-10T19:45:19.322164Z"
    }
   },
   "outputs": [],
   "source": [
    "# vocab dataframe file\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a08e93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:45:19.371760Z",
     "start_time": "2022-04-10T19:45:19.339864Z"
    }
   },
   "outputs": [],
   "source": [
    "# token definition\n",
    "token_model = BertTokenizer(vocab_file, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59b9511a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:51:40.800226Z",
     "start_time": "2022-04-10T19:45:19.374015Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoding\n",
    "df['text'] = df['text'].apply(encode_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347276ad",
   "metadata": {},
   "source": [
    "## 3.3 Data Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16510261",
   "metadata": {},
   "source": [
    "###### 5.1 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c318ce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:51:41.043975Z",
     "start_time": "2022-04-10T19:51:40.800226Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['id', 'date', 'query', 'user'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fefd822",
   "metadata": {},
   "source": [
    "## 3.4 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6a695b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:51:45.871881Z",
     "start_time": "2022-04-10T19:51:41.045606Z"
    }
   },
   "outputs": [],
   "source": [
    "# changing dataframe to lists\n",
    "sentence = df['text'].to_list()\n",
    "sentiment = df['sentiment'].to_list()\n",
    "\n",
    "dataset = [[sent, sentiment[i], len(sent)] for i, sent in enumerate(sentence)]\n",
    "random.shuffle(dataset)\n",
    "dataset = [(sent[0], sent[1])\n",
    "          for sent in dataset if sent[2] > 7] # droping rows with 7 words or less\n",
    "\n",
    "# parameters\n",
    "BATCH_SIZE = 32\n",
    "NB_BATCHES = len(df) // BATCH_SIZE\n",
    "NB_BATCHES_TEST = NB_BATCHES // 10\n",
    "\n",
    "# changing dataframe to tensorflow format\n",
    "tf_dataset = tf.data.Dataset.from_generator(lambda: dataset, output_types=(tf.int32, tf.int32))\n",
    "\n",
    "# adding padds\n",
    "all_batched = tf_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None,), ()))\n",
    "\n",
    "# shuffle\n",
    "all_batched.shuffle(NB_BATCHES)\n",
    "\n",
    "# splits\n",
    "test = all_batched.take(NB_BATCHES_TEST)\n",
    "train = all_batched.skip(NB_BATCHES_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f46fae",
   "metadata": {},
   "source": [
    "# 4 Embeging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c4fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32769730",
   "metadata": {},
   "source": [
    "# 6.0 Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a45853",
   "metadata": {},
   "source": [
    "## 6.1 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2dc32c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T19:51:45.939541Z",
     "start_time": "2022-04-10T19:51:45.907073Z"
    }
   },
   "outputs": [],
   "source": [
    "class DCNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 vocab_size,\n",
    "                 emb_dim = 128,\n",
    "                 nb_filters = 50, \n",
    "                 FFN_units = 512,\n",
    "                 nb_classes = 2,\n",
    "                 dropout_rate = 0.1,\n",
    "                 training = False,\n",
    "                 name = 'dcnn'\n",
    "                ):\n",
    "        super(DCNN, self).__init__(name=name)\n",
    "\n",
    "        self.embedding = layers.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "\n",
    "        self.bigram = layers.Conv1D(filters = NB_FILTERS,\n",
    "                                   kernel_size = 2,\n",
    "                                   padding = 'valid',\n",
    "                                   activation = 'relu')\n",
    "\n",
    "        self.trigram = layers.Conv1D(filters = NB_FILTERS,\n",
    "                                   kernel_size = 3,\n",
    "                                   padding = 'valid',\n",
    "                                   activation = 'relu')\n",
    "\n",
    "        self.fourgram = layers.Conv1D(filters = NB_FILTERS,\n",
    "                                   kernel_size = 4,\n",
    "                                   padding = 'valid',\n",
    "                                   activation = 'relu')\n",
    "\n",
    "        self.pool = layers.GlobalAvgPool1D()\n",
    "\n",
    "        self.dense_1 = layers.Dense(units = FFN_UNITS, activation = 'relu')\n",
    "\n",
    "        self.dropout = layers.Dropout(rate = DROPOUT_RATE)\n",
    "\n",
    "        if NB_CLASSES == 2:\n",
    "            self.last_dense = layers.Dense(units = 1, activation = 'sigmoid')\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units = NB_CLASSES, activation = 'softmax')\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        x_1 = self.bigram(x)\n",
    "        x_1 = self.pool(x_1)\n",
    "        x_2 = self.trigram(x)\n",
    "        x_2 = self.pool(x_2)\n",
    "        x_3 = self.fourgram(x)\n",
    "        x_3 = self.pool(x_3)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3], axis=-1)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "\n",
    "        return output\n",
    "\n",
    "# parameters\n",
    "EMB_DIM = 200\n",
    "VOCAB_SIZE = len(token_model)\n",
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES = 2\n",
    "DROPOUT_RATE = 0.2\n",
    "NB_EPOCHS = 5\n",
    "\n",
    "# instanciate model\n",
    "Dcnn = DCNN(vocab_size = VOCAB_SIZE,\n",
    "           emb_dim = EMB_DIM, \n",
    "           nb_filters = NB_FILTERS,\n",
    "           FFN_units = FFN_UNITS,\n",
    "           nb_classes = NB_CLASSES,\n",
    "           dropout_rate = DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2df972",
   "metadata": {},
   "source": [
    "## 6.2 Creating a Save Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d69f26e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T20:45:04.123785Z",
     "start_time": "2022-04-10T20:45:04.108339Z"
    }
   },
   "outputs": [],
   "source": [
    "if NB_CLASSES ==2:\n",
    "    Dcnn.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "else:\n",
    "    Dcnn.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint_patch = 'D:\\\\My Drive\\\\Pessoal\\\\Projetos\\\\sentiment_analysis\\\\exports'\n",
    "\n",
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_patch, max_to_keep=1)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.last_checkpoint)\n",
    "    print('Latest checkpoint restored!')\n",
    "\n",
    "class MyCustomCallBack(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ckpt_manager.save()\n",
    "        print(f'Checkpoint saved at: {checkpoint_patch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f308b8",
   "metadata": {},
   "source": [
    "## 6.3 Fiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd2b2a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T23:07:44.460457Z",
     "start_time": "2022-04-10T20:45:11.493499Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  36328/Unknown - 2936s 81ms/step - loss: 0.3750 - accuracy: 0.8326Checkpoint saved at: D:\\My Drive\\Pessoal\\Projetos\\sentiment_analysis\\exports\n",
      "36328/36328 [==============================] - 2937s 81ms/step - loss: 0.3750 - accuracy: 0.8326\n",
      "Epoch 2/5\n",
      "21707/36328 [================>.............] - ETA: 1:02:52 - loss: 0.3473 - accuracy: 0.8477"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mDcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNB_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mMyCustomCallBack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mD:\\My Drive\\Pessoal\\Projetos\\environments\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = Dcnn.fit(train,\n",
    "                  epochs=NB_EPOCHS,\n",
    "                  callbacks=[MyCustomCallBack()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
